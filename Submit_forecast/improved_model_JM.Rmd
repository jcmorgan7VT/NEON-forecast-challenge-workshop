---
title: "JM Improved Model"
author: "John Morgan"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

Copy and pasted from JM_first_forecast, then modified to test out different modeling frameworks.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-packages, echo = F, warning=F, message=F}
## install.packages('remotes')
## install.packages('fpp3') # package for applying simple forecasting methods
## install.packages('tsibble') # package for dealing with time series data sets and tsibble objects
## install.packages('tidyverse') # collection of R packages for data manipulation, analysis, and visualisation
## install.packages('lubridate') # working with dates and times
#remotes::install_github('eco4cast/neon4cast') # package from NEON4cast challenge organisers to assist with forecast building and submission

# Load packages
library(tidyverse)
library(lubridate)
library(tsibble)
library(fable)
library(neon4cast)
library(feasts)
library(urca)

```

```{r}
#copying fable method from text book
#set up targets
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz',
                    show_col_types = FALSE)
max_horizon <- 35
var <- "temperature"
site <- "BARC"

#calculate the horizon
forecast_starts <- targets |> 
  dplyr::filter(!is.na(observation) & site_id == site & variable == var) |> 
  # Start the day after the most recent non-NA value
  dplyr::summarise(start_date = max(datetime) + lubridate::days(1)) |>  # Date
  dplyr::mutate(h = (Sys.Date() - start_date) + max_horizon,
                h = as.numeric(h)) |>  # Horizon value
  dplyr::ungroup()

forecast_starts

#convert targets into a time-series tibble
targets_use <- targets |> 
  dplyr::filter(site_id == site,
                variable == var) %>%
  tsibble::as_tsibble(key = c('variable', 'site_id'), index = 'datetime') |> 
  tsibble::fill_gaps()   # add NA values up to today (index)

#set up what model to use- example is RW, for random walk
RW_model <- targets_use |> 
  fabletools::model(RW = fable::ARIMA(observation ~ drift())) 

#generate a forecast for h number of time steps into the future
forecast <- RW_model |>  
  fabletools::generate(h = forecast_starts$h, bootstrap = T, times = 10)

#reformat forecast
RW_forecasts_EFI <- forecast %>%
  rename(parameter = .rep,
         prediction = .sim) %>%
  # For the EFI challenge we only want the forecast for future
  #filter(datetime > Sys.Date()) %>%
  group_by(site_id, variable) %>%
  mutate(reference_datetime = Sys.Date(),
         family = "ensemble",
         model_id = "persistenceRW") %>%
  select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)

#plot forecast
RW_forecasts_EFI |>
  filter(variable == "temperature") |>
  ggplot(aes(x = datetime, y = prediction, group = parameter)) +
  geom_line() + 
  geom_vline(aes(xintercept = reference_datetime), color = "blue") +
  facet_wrap(~site_id)
```

Above code works, but I am going to try the machine learning techniques with all of the possible input variables
```{r}
#pick an arbitrary day to start
start <- ymd("2023-07-01")
horizon <- ymd("2023-7-31")

#copying fable method from text book
#set up targets
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz',
                    show_col_types = FALSE)
max_horizon <- 31 #h from Quinn's script
var <- "temperature"
site <- "BARC"

# read in the sites data
aquatic_sites <- read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |>
  dplyr::filter(aquatics == 1)

lake_sites <- aquatic_sites %>%
  filter(field_site_subtype == 'Lake')

# Past stacked weather
noaa_past_s3 <- neon4cast::noaa_stage3()

variables <- c("air_temperature", 
               "air_pressure",
               "relative_humidity",
               "surface_downwelling_longwave_flux_in_air",
               "surface_downwelling_shortwave_flux_in_air",
               "precipitation_flux",
               "eastward_wind", 
               "northward_wind")
#Other variable names can be found at https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html#stage-3

noaa_past <- noaa_past_s3  |> 
  dplyr::filter(site_id %in% lake_sites$field_site_id,
                datetime >= ymd('2017-01-01'),
                variable %in% variables) |> 
  dplyr::collect()

# aggregate the past to mean values
noaa_past_mean <- noaa_past |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |> 
  pivot_wider(names_from = variable, values_from = prediction) |> 
  # convert air temp to C
  mutate(air_temperature = air_temperature - 273.15) |> 
  dplyr::filter(datetime < start) #site_id == site & 

forecast_sites <- unique(noaa_past_mean$site_id)
#data input to train the model
##########
#add a lagged temperature column

#convert targets into a time-series tibble
targets_use <- targets |> 
  dplyr::filter(site_id %in% forecast_sites,
                variable == var,
                datetime < start)  |> 
  group_by(site_id) |> 
  mutate(lagged = lag(observation, default = NA))|> 
  left_join(noaa_past_mean, by = join_by(datetime, site_id)) |> 
  tsibble::as_tsibble(key = c('variable', 'site_id'), index = 'datetime') |>
  tsibble::fill_gaps()   # add NA values up to today (index)



ggplot(targets_use)+
  geom_point(aes(x = lagged, y = observation), alpha = 0.2, color = "grey")+
  facet_wrap(~site_id)
#atmospheric drivers to my horizon date
#forecast_starts <- noaa_past_mean |> 
  #dplyr::filter(datetime <= start) #|> 
  #tsibble::as_tsibble(key = c('variable', 'site_id'), index = 'datetime')
##########

#get actual observationgs to see how good my model performed
actual_obs <- targets |> 
  dplyr::filter(site_id %in% forecast_sites,
                variable == var,
                datetime >= start,
                datetime <= horizon) |> 
  group_by(site_id) |> 
  tsibble::as_tsibble(key = c('variable', 'site_id'), index = 'datetime') |>
  tsibble::fill_gaps()


#right now I am training off of the actual observations, need to be training off of the NOAA level 3 forecasts
fit <- targets_use %>% 
  fabletools::model(
    #arima = ARIMA(observation),
    lm = TSLM(observation ~ trend() + season()),
    var = VAR(observation)
  )

fc <- fit %>% 
  forecast(h = max_horizon)
fc

fc %>% 
  hilo(level = 95)

filter(fc, site_id == "PRLA") %>% 
  autoplot(targets_use |> 
             ungroup() |> 
             filter(datetime >= start,
                    datetime <= horizon,
                    site_id == "BARC"))+
  facet_wrap(~.model, ncol = 1)+
  geom_point(data = filter(actual_obs, site_id == "PRLA"), aes(x = datetime, y = observation))


actual_obs |> 
  autoplot(observation)+
  facet_wrap(~site_id, ncol = 1)

actual_obs |> 
  autolayer(observation) |> 
  autolayer(fc)
#   fabletools::model(linear_reg = fable::linear_reg(observation ~ air_pressure + air_temperature + eastward_wind + northward_wind + precipitation_flux + relative_humidity + surface_downwelling_longwave_flux_in_air + surface_downwelling_shortwave_flux_in_air + drift())) 
# 
# test <- fable::linear_reg(mode = "regression", engine = "lm", penalty = NULL, mixture = NULL)
#generate a forecast for h number of time steps into the future
#need to iterate through each ensemble member maybe 10 times each
forecast <- RW_model |>  
  fabletools::generate(h = max_horizon, bootstrap = T, times = 200)

#reformat forecast
RW_forecasts_EFI <- forecast %>%
  rename(parameter = .rep,
         prediction = .sim) %>%
  # For the EFI challenge we only want the forecast for future
  #filter(datetime > Sys.Date()) %>%
  group_by(site_id, variable) %>%
  mutate(reference_datetime = Sys.Date(),
         family = "ensemble",
         model_id = "persistenceRW") %>%
  select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)

#plot forecast
RW_forecasts_EFI |>
  filter(variable == "temperature") |>
  ggplot(aes(x = datetime, y = prediction, group = parameter)) +
  geom_line() + 
  geom_vline(aes(xintercept = reference_datetime), color = "blue") +
  facet_wrap(~site_id)
```

```{r}
#determining the accuracy of the 31 day model


gg <- targets_use |> 
  filter(site_id == "BARC") %>% 
  mutate(my_xreg = rnorm(nrow(.))) |> 
  fabletools::model(
    arima = ARIMA(observation ~ my_xreg),
    arima1 = ARIMA(observation),
    lm = TSLM(observation ~ trend() + season()),
    var = VAR(observation)
  ) |> 
  forecast(h = "31 days")
gg |> 
  accuracy(actual_obs)
gg |> 
  autoplot(level = c(95))

gg <- targets_use |> 
  filter(site_id == "BARC") %>% 
  select(datetime, site_id, variable, observation, air) |> 
  fabletools::model(arima = ARIMA(observation )) |> 
  forecast(h = "31 days")

gg |> 
  accuracy(actual_obs)
gg |> 
  autoplot(level = c(95))

tsibbledata::global_economy %>%
  filter(Country == "Australia") %>%
  model(ARIMA(log(GDP) ~ Population))

#determin if my data is stationary
test <- targets_use |> 
  filter(site_id == "BARC")

test |> ACF(observation) |>
  autoplot() + labs(subtitle = "Observed water temp")
#autocorrelation is very high 1 day and 21 days away
#daily change is not a random amount-  auto correlated, indicating that the data is non-stationary
test |> ACF(difference(observation))
  autoplot() + 
  labs(subtitle = "Changes in observed water temp")

#testing tslm model  

model(test, TSLM(observation ~ lagged + air_pressure + air_temperature + eastward_wind + northward_wind + precipitation_flux + relative_humidity + surface_downwelling_longwave_flux_in_air + surface_downwelling_shortwave_flux_in_air)) |>
  report()

test |> 
  model(TSLM(observation ~ lagged + air_temperature + surface_downwelling_shortwave_flux_in_air)) |>
  report()

test |> 
  model(TSLM(observation ~ lagged + air_temperature)) |> 
  forecast()

fit <- targets_use %>% 
  fabletools::model(
    #arima = ARIMA(observation),
    lm = TSLM(observation ~ trend() + season()),
    var = VAR(observation),
    lm2 = TSLM(observation ~ lagged + air_temperature)
  )
fit |> 
  forecast(h = "31 days") |> 
  autoplot()

report()

#trying again
start <- "2023-05-31"

all_data <- targets |> 
  dplyr::filter(site_id %in% forecast_sites,
                variable == var)  |> 
  group_by(site_id) |>
  right_join(noaa_past_mean, by = join_by(datetime, site_id)) |> 
  mutate(lagged = lag(observation, default = NA)) |> 
  select(datetime, site_id, observation, lagged, air_temperature) |> 
  #pivot_longer(!c(datetime, site_id), names_to = "variable", values_to = "value") |> 
  tsibble::as_tsibble(key = c('site_id'), index = 'datetime') |>
  tsibble::fill_gaps()

train <- all_data |> 
  dplyr::filter(datetime < start)

test <- all_data |> 
  dplyr::filter(datetime > start)

train |> 
  model(TSLM(observation ~ lagged + air_temperature)) |> 
  #forecast(h = "31 days", new_data = test) |> 
  report()
```


```{r}
#trying to figure out why I can't run the linear model using the additional variable
library(tsibbledata)
library(fpp3)

us_change |>
  model(TSLM(Consumption ~ Income)) |>
  report()

fit_consMR <- us_change |>
  model(tslm = TSLM(Consumption ~ Income + Production +
                                    Unemployment + Savings))
report(fit_consMR)

augment(fit_consMR) |>
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Consumption, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = NULL,
    title = "Percent change in US consumption expenditure"
  ) +
  scale_colour_manual(values=c(Data="black",Fitted="#D55E00")) +
  guides(colour = guide_legend(title = NULL))

#applying this example to my data
btrain <- train |> 
  filter(site_id == "BARC")
btest <- test |> 
  filter(site_id == "BARC")
ball <- all_data |> 
  filter(site_id == "BARC")

btest2 <- btest
btest2$observation <- NA
btest2$lagged <- NA

btrain2 <- bind_rows(btrain, btest2)
ball |>
  model(TSLM(observation ~ lagged)) |>
  report()

btrain |>
  model(tslm = TSLM(observation ~ air_temperature + lag(observation))) |> 
  forecast(new_data = btest) |> 
  autoplot()+
  geom_line(data =  filter(btrain, datetime > "2023-01-01"), aes(x = datetime, y = observation))+
  geom_point(data = btest,  aes(x = datetime, y = observation))
#doesn't work when I do forecast- is this because it is missing the lagged and air_temperature?


augment(bfit) |>
  ggplot(aes(x = datetime)) +
  geom_line(aes(y = observation, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = NULL,
    title = "Water temperature in BARC"
  ) +
  scale_colour_manual(values=c(Data="black",Fitted="blue")) +
  guides(colour = guide_legend(title = NULL))

#have a working model, but I cannot figure out how to include a lagged term. It is not moving iteratively, so how do I include the freshest prediciton from the day before?

# i think i mightve done it in the code above?

```


```{r get-targets, message=F}
#read in the targets data
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz')

# read in the sites data
aquatic_sites <- read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |>
  dplyr::filter(aquatics == 1)

lake_sites <- aquatic_sites %>%
  filter(field_site_subtype == 'Lake')

# Filter the targets
targets <- targets %>%
  filter(site_id %in% lake_sites$field_site_id,
         variable == 'temperature')
```


```{r get-NOAA-past, message = F}

# Past stacked weather
noaa_past_s3 <- neon4cast::noaa_stage3()

variables <- c("air_temperature", "eastward_wind", "northward_wind")
#Other variable names can be found at https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html#stage-3

noaa_past <- noaa_past_s3  |> 
  dplyr::filter(site_id %in% lake_sites$field_site_id,
                datetime >= ymd('2017-01-01'),
                variable %in% variables) |> 
  dplyr::collect()

# aggregate the past to mean values
noaa_past_mean <- noaa_past |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |> 
  pivot_wider(names_from = variable, values_from = prediction) |> 
  # convert air temp to C
  mutate(air_temperature = air_temperature - 273.15)

```

```{r get-NOAA-future, message = F}
# Future weather
# New forecast only available at 5am UTC the next day
forecast_date <- Sys.Date() 
noaa_date <- forecast_date - days(1)

noaa_future_s3 <- neon4cast::noaa_stage2(start_date = as.character(noaa_date))
variables <- c("air_temperature", "eastward_wind", "northward_wind")

noaa_future <- noaa_future_s3 |> 
  dplyr::filter(datetime >= forecast_date,
                site_id %in% lake_sites$field_site_id,
                variable %in% variables) |> 
  collect()

noaa_future_daily <- noaa_future |> 
  mutate(datetime = as_date(datetime)) |> 
  # mean daily forecasts at each site per ensemble
  group_by(datetime, site_id, parameter, variable) |> 
  summarize(prediction = mean(prediction)) |>
  pivot_wider(names_from = variable, values_from = prediction) |>
  # convert to Celsius
  mutate(air_temperature = air_temperature - 273.15) |> 
  select(datetime, site_id, air_temperature, eastward_wind, northward_wind, parameter)
```

```{r model-setup}
# Generate a dataframe to fit the model to 
targets_lm <- targets |> 
  filter(variable == 'temperature') |>
  pivot_wider(names_from = 'variable', values_from = 'observation') |> 
  left_join(noaa_past_mean, 
            by = c("datetime","site_id"))

# Loop through each site to fit the model
temp_lm_forecast <- NULL

```


```{r}
#code ripped from Mary's module 6, set up for including uncertainty
forecast_start_date <- forecast_date


#number of days we are predicting into the future
forecast_horizon <- 7
#vector of dates that we want to predict for
forecasted_dates <- seq(from = ymd(forecast_start_date), to = ymd(forecast_start_date) + forecast_horizon, by = "day")
```


```{r forecast-loop}
forecast_df <- NULL
#for loop to fit a linear regression on every site
for(i in 1:length(lake_sites$field_site_id)) {  
  
  example_site <- lake_sites$field_site_id[i]
  
  #past data to build the lm
  site_target <- targets_lm |>
    filter(site_id == example_site)

  #future data to run on the lm
  noaa_future_site <- noaa_future_daily |> 
    filter(site_id == example_site) %>% 
    filter(datetime <= max(forecasted_dates))
  
  #fitting linear model to past data
  fit <- lm(site_target$temperature ~ site_target$air_temperature + site_target$eastward_wind + site_target$northward_wind)
  fit_sum <- summary(fit)
  fit_sum_df <- as.data.frame(fit_sum$coefficients)
  
  #coeffs <- round(fit$coefficients, 2)
  coeffs <- fit_sum_df[,1]
  params_se <- fit_sum_df[,2]


  #create df containing distribution of parameter uncertainty, done for each new lm for each site
  param_df <- data.frame(b_beta = rnorm(31, coeffs[1], params_se[1]),
                         airT_beta = rnorm(31, coeffs[2], params_se[2]),
                         eWind_beta = rnorm(31, coeffs[3], params_se[3]),
                         nWind_beta = rnorm(31, coeffs[4], params_se[4]))

  #Process uncertainty- uncertainty due to how we model or represent this system
  mod <- predict(fit, site_target)
  residuals <- mod - site_target$temperature
  sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma
  process_unc <- rnorm(n = 31, mean = 0, sd = sigma)

  # initial condition uncertainty- not included bc I don't have any antecedent conditions
  #ic_sd <- 0.1 
  #ic_uc <- rnorm(n = n_members, mean = curr_wt, sd = ic_sd)

  #run a model run for each ensemble member, incorporating the different sources of uncertainty
  for(x in 1:length(forecasted_dates)) {
    # use linear regression to forecast water temperature for each ensemble member
    #iterating through each day, so filter for day each day individually to predict
    site_drivers <- noaa_future_site %>%
      filter(datetime == forecasted_dates[x]) %>% 
      bind_cols(param_df)
    #defining components of the multi-linear regression- using ones with uncertainty
    b <- site_drivers$b_beta
    airT <- site_drivers$air_temperature * site_drivers$airT_beta
    east <- site_drivers$eastward_wind * site_drivers$eWind_beta
    west <- site_drivers$northward_wind * site_drivers$nWind_beta

    #multi linear regression
    forecasted_temperature <- b + airT + east + west + process_unc
    
    # put all the relevant information into a tibble that we can bind together
    # site_drivers$prediction <- forecasted_temperature
    # if(x == 1) loop2 <- site_drivers
    # if(x > 1) loop2 <- dplyr::bind_rows(loop2, site_drivers)
    
    curr_site_df <- tibble(datetime = rep(forecasted_dates[x], times = 31),
                         site_id = example_site,
                         parameter = 0:30,
                         prediction = forecasted_temperature,
                         variable = "temperature") #Change this if you are forecasting a different variable
  
  forecast_df <- dplyr::bind_rows(forecast_df, curr_site_df)
    

  }
    
  
  
  #temp_lm_forecast <- dplyr::bind_rows(temp_lm_forecast, loop2)
  message(example_site, ' temperature forecast run')
  
}
```

```{r make-standard}
# Make forecast fit the EFI standards
# Remember to change the model_id when you make changes to the model structure!
my_model_id <- 'example_ID'
my_model_id2 <- 'example_ID2'


temp_lm_forecast_EFI <- forecast_df %>%
  filter(datetime > forecast_date) %>%
  mutate(model_id = my_model_id,
         reference_datetime = forecast_date,
         family = 'ensemble',
         parameter = as.character(parameter),
         variable = "temperature") %>%
  select(datetime, reference_datetime, site_id, family, parameter, variable, prediction, model_id)

```

```{r write-forecast}
# Write the forecast to file
theme <- 'aquatics'
date <- temp_lm_forecast_EFI$reference_datetime[1]
forecast_name_1 <- paste0(temp_lm_forecast_EFI$model_id[1], ".csv")
forecast_file_1 <- paste(theme, date, forecast_name_1, sep = '-')
forecast_file_1


if (!dir.exists('Forecasts')) {
  dir.create('Forecasts')
}

write_csv(temp_lm_forecast_EFI, file.path('Forecasts',forecast_file_1))

neon4cast::forecast_output_validator(file.path('Forecasts',forecast_file_1))

```


```{r submit-forecast}

## # can uses the neon4cast::forecast_output_validator() to check the forecast is in the right format

# UNCOMMMENT THIS WHEN YOU ARE READY TO SUBMIT
neon4cast::submit(forecast_file = file.path('Forecasts', forecast_file_1),
                   ask = FALSE) # if ask = T (default), it will produce a pop-up box asking if you want to submit


```



```{r}
#final plot showing all of my ensemble members with all sources of uncertainty
#plots of forecasts including uncertainty
# temp_lm_forecast_EFI %>% 
#   filter(variable == 'temperature') %>%
#   ggplot(.,aes(x=datetime, y=prediction, group = parameter)) + 
#   geom_point(data = targets,aes(x=datetime, y=observation, group = 'obs'), colour = 'darkblue') +
#   geom_line(alpha = 0.3, aes(colour = 'ensemble member (parameter)')) + 
#   facet_wrap(~site_id, scales = 'free_y') +
#   scale_x_date(expand = c(0,0), date_labels = "%d %b") +
#   labs(y = 'value') +
#   geom_vline(aes(linetype = 'reference_datetime', xintercept = Sys.Date()), colour = 'blue', size = 1.5) +
#   labs(title = 'site_id', subtitle = 'variable = temperature', caption = 'prediction') + 
#   annotate("text", x = Sys.Date() - days(10), y = 20, label = "past")  +
#   annotate("text", x = Sys.Date() + days(12), y = 20, label = "future")  +
#   theme_bw() +
#   coord_cartesian(xlim = c(min(temp_lm_forecast$datetime) - days(15),
#                            Sys.Date() + days(7))) +
#   scale_linetype_manual(values = 'dashed', name = '') +
#   scale_colour_manual(values = 'darkgrey', name = '') +
#   theme(strip.text = element_text(colour = 'orange'),
#         axis.title.y = element_text(colour = 'green'),
#         axis.title.x = element_text(colour = 'red'),
#         axis.text.y = element_text(colour = 'purple'),
#         axis.text.x = element_text(colour = 'red'),
#         plot.caption = element_text(hjust = 0, colour = 'purple'),
#         plot.title = element_text(colour = 'orange'), 
targets2 <- filter(targets, datetime >= forecast_date - days(14))

ggplot() +
    geom_point(data = targets2, aes(x = datetime, y = observation, group = "obs"), color = "black") +
    geom_line(data = temp_lm_forecast_EFI, aes(x = datetime, y = prediction, group = parameter), color = "grey", alpha = 0.9) +
    geom_vline(xintercept = as_date(forecast_date), linetype = "dashed") +
    ylab("Temperature (\u00B0C)") +
  lims(x = c(forecast_date - days(14), max(temp_lm_forecast_EFI$datetime)))+
    facet_wrap(~site_id, scales = 'free_y') +
    theme_bw(base_size = 12)

#funnel shape occurs when you have initial conditions, and when your driver uncertainty is high- when you have something sensitive to weather conditions

#adding the concept will reduce initial uncertainty

# to add more ensemble members- randomly sample with replacement of noaa predictions, up to however many ensemble members you want. IF ensemble members are not equally likely, then you need to incorporate weighting.
```

Describe what I did at the bottom of the Markdown, deadline is Thursday at midnight